{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI_6PqR_wt43"
      },
      "source": [
        "Firstly, importing the packages and reading the values from the dataset.\n",
        "Note the path needs to be changed with the path where the dataset is located.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2PQEjUWwkp4",
        "outputId": "8d7ca3fc-0b3b-4829-d238-b87920b2c88e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "from csv import reader\n",
        "import pandas as pd\n",
        "import collections\n",
        "import nltk\n",
        "import pickle\n",
        "import operator\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6zSiEoj7i5s"
      },
      "source": [
        "#importing the dataset\n",
        "ds=[]\n",
        "with open(\"--path to dataset--\", 'r',encoding='utf-8') as read_obj:\n",
        "\tcsv_reader = reader(read_obj)\n",
        "\tfor row in csv_reader:\n",
        "\t\tds.append(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxZNaB-Zxxkc"
      },
      "source": [
        "Declaring variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msB0OkBtxwie"
      },
      "source": [
        "lineLength=20 # determine how long to be the line read from dataset\n",
        "b_s=128 #batch size\n",
        "DROPOUT=0.4\n",
        "LAYER_SIZE=300\n",
        "maxLen=20\n",
        "valSize=400 #reserve first 400 rows for validation--to be changed to ~20% of the traning size\n",
        "EPOCHS=200\n",
        "#Define callback to monitro condition if training has to stop beore the epochs are fnished\n",
        "CALL_BACKS = EarlyStopping(monitor='loss', patience=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V60FYs1ExLoD"
      },
      "source": [
        "In this dataset, questions are located in rows 1 and 2, and the answers are located in row 3. However we are ignoring row 2 and only keeping row 1 as a question. For questions/answers longer that maximum line length, the sentence will be shortened to the first lineLength words of the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPC0FXNlxKkm"
      },
      "source": [
        "questions_v0=[]\n",
        "answers_v0=[]\n",
        "for line in ds:\n",
        "\tquestions_v0.append(line[1])\n",
        "\tanswers_v0.append(line[3])\n",
        "#The dataset has many entries at this point so we are selecting only the first 3700\n",
        "#this is done in order to reduce the testing size for faster calculations and because it takes up\n",
        "#less ram\n",
        "answers_v1=[]\n",
        "questions_v1=[]\n",
        "#Since our maxlength is 20, only the first 19 words of each question/answer are taken under consideration\n",
        "str=\" \"\n",
        "for line in answers_v0:\n",
        "\tif(len(line.split())>lineLength):\n",
        "\t\tmid=line.split()[:lineLength]\n",
        "\t\tanswers_v1.append(str.join(mid))\n",
        "\telse:\n",
        "\t\tanswers_v1.append(line)\n",
        "\n",
        "for line in questions_v0:\n",
        "\tif(len(line.split())>lineLength):\n",
        "\t\tmid=line.split()[:lineLength]\n",
        "\t\tquestions_v1.append(str.join(mid))\n",
        "\telse:\n",
        "\t\tquestions_v1.append(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgeqS08myX6o"
      },
      "source": [
        "Due to the large amount of time it would take to process all the dataset, we are only taking the first 8000 entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vv3ocNQ7txX"
      },
      "source": [
        "#answers_v1=answers_v1[:8000]\n",
        "#questions_v1=questions_v1[:8000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG1XIWmBx5Ip"
      },
      "source": [
        "The following function sever to remove all the noise from the dataset including:\n",
        "\n",
        "*   Symbols\n",
        "*   Abbreviations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IN866BiyJOg"
      },
      "source": [
        "#removing not important symbols and abbreviations\n",
        "def clean_text(text):\n",
        "\ttext=text.lower()\n",
        "\ttext=re.sub(r\"i'm\",\"I am\",text)\n",
        "\ttext=re.sub(r\"he's\",\"he is\",text)\n",
        "\ttext=re.sub(r\"she's\",\"she is\",text)\n",
        "\ttext=re.sub(r\"that's\",\"that is\",text)\n",
        "\ttext=re.sub(r\"what's\",\"what is\",text)\n",
        "\ttext=re.sub(r\"<br />\",\"\",text)\n",
        "\ttext=re.sub(r\"/n\",\" \",text)\n",
        "\ttext=re.sub(r\"\\\\n\",\" \",text)\n",
        "\ttext=re.sub(r\"\\'ll\",\" will\",text)\n",
        "\ttext=re.sub(r\"\\'ve\",\" have\",text)\n",
        "\ttext=re.sub(r\"\\'re\",\" are\",text)\n",
        "\ttext=re.sub(r\"\\'d\",\" would\",text)\n",
        "\ttext=re.sub(r\"won't\",\"will not\",text)\n",
        "\ttext=re.sub(r\"can't\",\"cannot\",text)\n",
        "\ttext=re.sub(r\"https\",\" \",text)\n",
        "\ttext=re.sub(r\"www.\",\" \",text)\n",
        "\ttext=re.sub(r\".com\",\" \",text)\n",
        "\ttext=re.sub(r\"Ã¿\",\" \",text)\n",
        "\ttext=re.sub(r\"[-()\\\"#/@;:<>{}+-=.?,|]\",\" \",text)\n",
        "\treturn text\n",
        "\n",
        "#Applying the above function on each question/answer\n",
        "questions=[]\n",
        "answers=[]\n",
        "for question in questions_v1:\n",
        "\t question=clean_text(question)\n",
        "\t questions.append(question)\n",
        "\n",
        "for answer in answers_v1:\n",
        "\t answer=clean_text(answer)\n",
        "\t answers.append(answer)\n",
        "\n",
        "maxlen = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwHq5PDFyqjM"
      },
      "source": [
        "Adding <BOS> and <EOS> tags to the answers to denote beginning of sentences and ending of sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhNrCMDDy1TS"
      },
      "source": [
        "final_target_v0 = ['BOS '+i+' EOS' for i in answers]\n",
        "context_v0 = list(questions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk7klN3ky8zH"
      },
      "source": [
        "Removing Extra spaces '    ' -> ' '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZeieTaAy47p"
      },
      "source": [
        "final_target_v0 = list(pd.Series(final_target_v0).map(lambda x: re.sub(' +', ' ', x)))\n",
        "context_v0 = list(pd.Series(questions).map(lambda x: re.sub(' +', ' ', x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqdGkBCIzGyU"
      },
      "source": [
        "Creating a counts list to store all the words in questions and answers. This list is later converted to a dictionary that maps every word to an index, and this one will finally be reversed so that every index points to its corresponding word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbogFuLRzF9M"
      },
      "source": [
        "counts = {}\n",
        "for words in context_v0+final_target_v0:\n",
        "    for word in words.split():\n",
        "        counts[word] = counts.get(word,0) + 1\n",
        "#create a dictionary to associate each word with a specific index\n",
        "word_to_index = {}\n",
        "for pos,i in enumerate(counts.keys()):\n",
        "\tword_to_index[i] = pos\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOS5mIhozkxV"
      },
      "source": [
        "Converting answers and questions to integer sequences based on the word_to_index dictionary, delclared earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gciEKC0MzszF"
      },
      "source": [
        "final_target = np.array([[word_to_index[w] for w in i.split()] for i in final_target_v0])\n",
        "context = np.array([[word_to_index[w] for w in i.split()] for i in context_v0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcUfSUQG0SgS"
      },
      "source": [
        "Here begins the seq2seq model part assignings new names to the lists as not to create confusion with the previous part.\n",
        "final_target_1 refers to the answers\n",
        "context_1 refers to the questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kngGFCh7WRny"
      },
      "source": [
        "final_target_1 = final_target\n",
        "context_1 = context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5RwIuon06gl"
      },
      "source": [
        "Before the training the data will be padded so that every sentence has the same length. The padding process is done by adding zeros to the end of every sentence. However at this point we have some words that are mapped to zeros in our lists and dictionaries, and by incrementing the indexes of each word by 1 this problem is solved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ5WkTtZWWkR"
      },
      "source": [
        "# shift the indexes of the context and target arrays too\n",
        "for i,j in word_to_index.items():\n",
        "    word_to_index[i] = j+1\n",
        "# reverse dictionary\n",
        "index_to_word = {}\n",
        "for k,v in word_to_index.items():\n",
        "    index_to_word[v] = k\n",
        "\n",
        "for i in final_target_1:\n",
        "    for pos,j in enumerate(i): i[pos] = j + 1\n",
        "for i in context_1:\n",
        "    for pos,j in enumerate(i): i[pos] = j + 1\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMOzGW1x1c1z"
      },
      "source": [
        "Read the embedded 50 dimenssional GloVe file.\n",
        "Note: replace the path with where the GloVe file is located"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M0KWFzIWXBL"
      },
      "source": [
        "# read in the 50 dimensional GloVe embeddings\n",
        "def read_glove_vecs(file):\n",
        "    with open(file, 'r',encoding='utf-8') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            word = line[0]\n",
        "            words.add(word)\n",
        "            word_to_vec_map[word] = np.array(line[1:], dtype=np.float64)\n",
        "\n",
        "    return words, word_to_vec_map\n",
        "\n",
        "words, word_to_vec_map = read_glove_vecs('/content/drive/My Drive/glove.6B.50d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfaubFBm14iQ"
      },
      "source": [
        "Create an embedding matrix and add all the vecorized words of our vocabulary to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbGxp1qRWb0b"
      },
      "source": [
        "vocab_size = len(word_to_index) + 1\n",
        "#setting validation size to be used for the validation set\n",
        "valSize=int(0.2*vocab_size)\n",
        "# initialize the embedding matrix that will be used (50 is the GloVe vector dimension)\n",
        "embedding_matrix = np.zeros((vocab_size, 50))\n",
        "for word,index in word_to_index.items():\n",
        "    try:\n",
        "        embedding_matrix[index, :] = word_to_vec_map[word.lower()]\n",
        "    except: continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WOCuBNJ2Hyd"
      },
      "source": [
        "Generator method to produce model inputs and outputs. Among all teh questions and answers only bacth_size number of each are processed at a time. Every time the generator is run batch_size questions and answers are produced for the traning process. These sentences are padded, and then the answers are moved one step forward and hot coded as the output of the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKYYELpqWdyc"
      },
      "source": [
        "def generator(questions,answers, batch_size=32):\n",
        "\tnum_samples = len(questions)\n",
        "\twhile True: # Loop forever so the generator never terminates\n",
        "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n",
        "\t\tfor offset in range(valSize, num_samples, batch_size):\n",
        "\t\t\t# Get the samples you'll use in this batch\n",
        "\t\t\t#batch_samples = samples[offset:offset+batch_size]\n",
        "\t\t\tquestion_samples = questions[offset:offset+batch_size]\n",
        "\t\t\tanswer_samples = answers[offset:offset+batch_size]\n",
        "\t\t\t# Initialise X_train and y_train arrays for this batch\n",
        "\t\t\tques_train = []\n",
        "\t\t\tans_train = []\n",
        "\t\t\tfor i in question_samples:\n",
        "\t\t\t\tques_train.append(i)\n",
        "\t\t\tfor i in answer_samples:\n",
        "\t\t\t\tans_train.append(i)\n",
        "            # Make sure they're numpy arrays (as opposed to lists)\n",
        "\t\t\tques_train = np.array(ques_train)\n",
        "\t\t\tans_train = np.array(ans_train)\n",
        "\t\t\tans_pad = sequence.pad_sequences(ans_train, maxlen = maxLen, dtype = 'int32', padding = 'post', truncating = 'post')\n",
        "\t\t\tques_pad = sequence.pad_sequences(ques_train, maxlen = maxLen, dtype = 'int32', padding = 'post', truncating = 'post')\n",
        "\t\t\t#print(ans_train)\n",
        "\t\t\t#print('ques',ques_pad)\n",
        "\t\t\tencoder_input_data = np.array( ques_pad )\n",
        "\t\t\tdecoder_input_data = np.array( ans_pad )\n",
        "\t\t\tfor i in range(len(ans_train)) :\n",
        "\t\t\t\tans_train[i] = ans_train[i][1:]\n",
        "\t\t\tpadded_answers = sequence.pad_sequences( ans_train , maxlen=maxLen , padding='post' )\n",
        "\t\t\tonehot_answers = utils.to_categorical( padded_answers , vocab_size )\n",
        "\t\t\tdecoder_output_data = np.array( onehot_answers )\n",
        "\t\t\tyield(encoder_input_data,decoder_input_data),decoder_output_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X29xMSRb2q7W"
      },
      "source": [
        "Similar decoder to the above but to produce validation results, this decoder is only run once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ctDC4LE8Of"
      },
      "source": [
        "def val_generator(questions,answers):\n",
        "  num_samples = len(questions)\n",
        "  question_samples = questions[:valSize]\n",
        "  answer_samples = answers[:valSize]\n",
        "  ques_train = []\n",
        "  ans_train = []\n",
        "  for i in question_samples:\n",
        "    ques_train.append(i)\n",
        "  for i in answer_samples:\n",
        "    ans_train.append(i)\n",
        "  ans_pad = sequence.pad_sequences(ans_train, maxlen = maxLen, dtype = 'int32', padding = 'post')\n",
        "  ques_pad = sequence.pad_sequences(ques_train, maxlen = maxLen, dtype = 'int32', padding = 'post')\n",
        "  encoder_input_data = np.array( ques_pad )\n",
        "  decoder_input_data = np.array( ans_pad )\n",
        "  for i in range(len(ans_train)) :\n",
        "    ans_train[i] = ans_train[i][1:]\n",
        "  padded_answers = sequence.pad_sequences( ans_train , maxlen=maxLen , padding='post' )\n",
        "  onehot_answers = utils.to_categorical( padded_answers , vocab_size )\n",
        "  decoder_output_data = np.array( onehot_answers )\n",
        "  return(encoder_input_data,decoder_input_data),decoder_output_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GngSjiR205U"
      },
      "source": [
        "Defining input layers\n",
        "\n",
        "*   input_context for the encoder\n",
        "*   input_target for the decoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy0AGiOgWfad"
      },
      "source": [
        "input_context = Input(shape = (maxLen, ), dtype = 'int32', name = 'input_context')\n",
        "input_target = Input(shape = (maxLen, ), dtype = 'int32', name = 'input_target')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtb1kwDc3CfK"
      },
      "source": [
        "Training model, includees and embeding layer. Each LSTM layer has size 300, there are three LSTM layers. each layer is composed of an encoder and adecoder where the encoder is fed data and passes it to its corresponing decoder. Finally dense layer, and dropout are applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs4l1bTHWg4N",
        "outputId": "6856f504-f3e7-4d94-8ac1-90b98e72bb62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "embed_layer = Embedding(input_dim = vocab_size, output_dim = 50, trainable = True,mask_zero=True )\n",
        "embed_layer.build((None,))\n",
        "embed_layer.set_weights([embedding_matrix],)\n",
        "input_ctx_embed = embed_layer(input_context)\n",
        "encoder_lstm,h1,c1 = LSTM(LAYER_SIZE, return_state = True, return_sequences = True)(input_ctx_embed)\n",
        "encoder_lstm2,h2,c2 = LSTM(LAYER_SIZE, return_state = True, return_sequences = True)(encoder_lstm)\n",
        "encoder_lstm2,h3,c3 = LSTM(LAYER_SIZE, return_state = True, return_sequences = True)(encoder_lstm2)\n",
        "encoder_states=[h1,c1,h3,c3]\n",
        "input_tar_embed = embed_layer(input_target)\n",
        "final1, context_h1, context_c1 = LSTM(LAYER_SIZE, return_state = True, return_sequences = True)(input_tar_embed, initial_state = [h1,c1])\n",
        "final2, context_h2, context_c2 = LSTM(LAYER_SIZE, return_state = True, return_sequences = True)(final1, initial_state = [h2,c2])\n",
        "final3, context_h3, context_c3 = LSTM(LAYER_SIZE, return_state = True, return_sequences = True)(final2, initial_state = [h3,c3])\n",
        "dense_layer=Dense(vocab_size, activation = 'softmax')\n",
        "output = TimeDistributed(dense_layer)(final3)\n",
        "output=Dropout(DROPOUT)(output)\n",
        "model = Model([input_context, input_target], output)\n",
        "Adam_1 = optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "model.compile(optimizer = Adam_1, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_target (InputLayer)       [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_context (InputLayer)      [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 20, 50)       632650      input_context[0][0]              \n",
            "                                                                 input_target[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 20, 300), (N 421200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, 20, 300), (N 421200      embedding[1][0]                  \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 20, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, 20, 300), (N 721200      lstm_3[0][0]                     \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 20, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, 20, 300), (N 721200      lstm_4[0][0]                     \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 20, 12653)    3808553     lstm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20, 12653)    0           time_distributed[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 8,168,403\n",
            "Trainable params: 8,168,403\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeMLTxoR4eYI"
      },
      "source": [
        "Train the model with the generated data, validation contains the validation data to be used. Epochs number, and steps for epoch since we are using generatora are also specified. Callbacks are defined in the top."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B0qeCQ2WjMf",
        "outputId": "5f88d438-087a-4ad7-ec9f-3fa9fea4108b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_generator=generator(context_1,final_target_1,batch_size=b_s)\n",
        "spe = context_1.shape[0]/b_s\n",
        "if context_1.shape[0] % b_s:\n",
        "    spe += 1\n",
        "validation=val_generator(context_1,final_target_1)\n",
        "model.fit(train_generator,validation_data=validation ,epochs = 400,steps_per_epoch=spe,callbacks=[CALL_BACKS])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "41/40 [==============================] - 22s 532ms/step - loss: 8.7958 - accuracy: 0.0626 - val_loss: 5.6632 - val_accuracy: 0.0500\n",
            "Epoch 2/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 8.2593 - accuracy: 0.0592 - val_loss: 5.6842 - val_accuracy: 0.0500\n",
            "Epoch 3/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 8.2606 - accuracy: 0.0522 - val_loss: 5.7064 - val_accuracy: 0.0500\n",
            "Epoch 4/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 8.2446 - accuracy: 0.0503 - val_loss: 5.7313 - val_accuracy: 0.0500\n",
            "Epoch 5/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 8.2076 - accuracy: 0.0499 - val_loss: 5.7454 - val_accuracy: 0.0500\n",
            "Epoch 6/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 8.2089 - accuracy: 0.0456 - val_loss: 5.7545 - val_accuracy: 0.0500\n",
            "Epoch 7/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 8.2103 - accuracy: 0.0432 - val_loss: 5.7666 - val_accuracy: 0.0529\n",
            "Epoch 8/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 8.2124 - accuracy: 0.0446 - val_loss: 5.7708 - val_accuracy: 0.0538\n",
            "Epoch 9/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 8.1960 - accuracy: 0.0439 - val_loss: 5.7674 - val_accuracy: 0.0563\n",
            "Epoch 10/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 8.2005 - accuracy: 0.0457 - val_loss: 5.7690 - val_accuracy: 0.0566\n",
            "Epoch 11/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 8.1841 - accuracy: 0.0459 - val_loss: 5.8021 - val_accuracy: 0.0569\n",
            "Epoch 12/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 8.1666 - accuracy: 0.0458 - val_loss: 5.7999 - val_accuracy: 0.0576\n",
            "Epoch 13/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 8.1725 - accuracy: 0.0434 - val_loss: 5.7973 - val_accuracy: 0.0568\n",
            "Epoch 14/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 8.1765 - accuracy: 0.0450 - val_loss: 5.7892 - val_accuracy: 0.0587\n",
            "Epoch 15/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 8.1643 - accuracy: 0.0450 - val_loss: 5.8122 - val_accuracy: 0.0580\n",
            "Epoch 16/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 8.1509 - accuracy: 0.0435 - val_loss: 5.7982 - val_accuracy: 0.0587\n",
            "Epoch 17/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 8.1506 - accuracy: 0.0449 - val_loss: 5.8360 - val_accuracy: 0.0579\n",
            "Epoch 18/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 8.1489 - accuracy: 0.0449 - val_loss: 5.8227 - val_accuracy: 0.0585\n",
            "Epoch 19/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 8.1575 - accuracy: 0.0454 - val_loss: 5.8129 - val_accuracy: 0.0582\n",
            "Epoch 20/400\n",
            "41/40 [==============================] - 14s 333ms/step - loss: 8.1208 - accuracy: 0.0448 - val_loss: 5.8165 - val_accuracy: 0.0590\n",
            "Epoch 21/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 8.1542 - accuracy: 0.0444 - val_loss: 5.7937 - val_accuracy: 0.0590\n",
            "Epoch 22/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 8.1527 - accuracy: 0.0457 - val_loss: 5.7935 - val_accuracy: 0.0599\n",
            "Epoch 23/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 8.1271 - accuracy: 0.0461 - val_loss: 5.7861 - val_accuracy: 0.0595\n",
            "Epoch 24/400\n",
            "41/40 [==============================] - 14s 333ms/step - loss: 8.1223 - accuracy: 0.0457 - val_loss: 5.8027 - val_accuracy: 0.0596\n",
            "Epoch 25/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 8.1001 - accuracy: 0.0462 - val_loss: 5.7885 - val_accuracy: 0.0595\n",
            "Epoch 26/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 8.1213 - accuracy: 0.0463 - val_loss: 5.7902 - val_accuracy: 0.0603\n",
            "Epoch 27/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 8.1062 - accuracy: 0.0499 - val_loss: 5.7695 - val_accuracy: 0.0742\n",
            "Epoch 28/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 8.0478 - accuracy: 0.0556 - val_loss: 5.7526 - val_accuracy: 0.0766\n",
            "Epoch 29/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 8.0392 - accuracy: 0.0579 - val_loss: 5.7496 - val_accuracy: 0.0481\n",
            "Epoch 30/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 8.0244 - accuracy: 0.0573 - val_loss: 5.7438 - val_accuracy: 0.0470\n",
            "Epoch 31/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 8.0380 - accuracy: 0.0587 - val_loss: 5.7393 - val_accuracy: 0.0492\n",
            "Epoch 32/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 8.0029 - accuracy: 0.0590 - val_loss: 5.7576 - val_accuracy: 0.0487\n",
            "Epoch 33/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.9917 - accuracy: 0.0588 - val_loss: 5.7720 - val_accuracy: 0.0515\n",
            "Epoch 34/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 7.9985 - accuracy: 0.0592 - val_loss: 5.7643 - val_accuracy: 0.0531\n",
            "Epoch 35/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 7.9772 - accuracy: 0.0597 - val_loss: 5.7542 - val_accuracy: 0.0533\n",
            "Epoch 36/400\n",
            "41/40 [==============================] - 14s 333ms/step - loss: 7.9552 - accuracy: 0.0613 - val_loss: 5.7904 - val_accuracy: 0.0538\n",
            "Epoch 37/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.9665 - accuracy: 0.0609 - val_loss: 5.7730 - val_accuracy: 0.0550\n",
            "Epoch 38/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 7.9606 - accuracy: 0.0612 - val_loss: 5.7790 - val_accuracy: 0.0566\n",
            "Epoch 39/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 7.9616 - accuracy: 0.0622 - val_loss: 5.7919 - val_accuracy: 0.0558\n",
            "Epoch 40/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.9189 - accuracy: 0.0626 - val_loss: 5.8181 - val_accuracy: 0.0579\n",
            "Epoch 41/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.9314 - accuracy: 0.0630 - val_loss: 5.7855 - val_accuracy: 0.0539\n",
            "Epoch 42/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 7.9262 - accuracy: 0.0628 - val_loss: 5.8169 - val_accuracy: 0.0535\n",
            "Epoch 43/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.8629 - accuracy: 0.0651 - val_loss: 5.8300 - val_accuracy: 0.0535\n",
            "Epoch 44/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.8459 - accuracy: 0.0669 - val_loss: 5.8354 - val_accuracy: 0.0558\n",
            "Epoch 45/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.8309 - accuracy: 0.0671 - val_loss: 5.8378 - val_accuracy: 0.0514\n",
            "Epoch 46/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.8777 - accuracy: 0.0675 - val_loss: 5.8608 - val_accuracy: 0.0520\n",
            "Epoch 47/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 7.8062 - accuracy: 0.0679 - val_loss: 5.8915 - val_accuracy: 0.0511\n",
            "Epoch 48/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.7868 - accuracy: 0.0684 - val_loss: 5.9260 - val_accuracy: 0.0496\n",
            "Epoch 49/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 7.7753 - accuracy: 0.0695 - val_loss: 5.9720 - val_accuracy: 0.0482\n",
            "Epoch 50/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.7894 - accuracy: 0.0699 - val_loss: 5.9539 - val_accuracy: 0.0469\n",
            "Epoch 51/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 7.8289 - accuracy: 0.0677 - val_loss: 5.9746 - val_accuracy: 0.0471\n",
            "Epoch 52/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.8197 - accuracy: 0.0683 - val_loss: 5.9704 - val_accuracy: 0.0467\n",
            "Epoch 53/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.7630 - accuracy: 0.0699 - val_loss: 5.9589 - val_accuracy: 0.0497\n",
            "Epoch 54/400\n",
            "41/40 [==============================] - 14s 332ms/step - loss: 7.7782 - accuracy: 0.0698 - val_loss: 5.9560 - val_accuracy: 0.0502\n",
            "Epoch 55/400\n",
            "41/40 [==============================] - 14s 333ms/step - loss: 7.7384 - accuracy: 0.0724 - val_loss: 5.9633 - val_accuracy: 0.0496\n",
            "Epoch 56/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 7.7190 - accuracy: 0.0711 - val_loss: 5.9598 - val_accuracy: 0.0496\n",
            "Epoch 57/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.7310 - accuracy: 0.0717 - val_loss: 5.9429 - val_accuracy: 0.0509\n",
            "Epoch 58/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.7154 - accuracy: 0.0726 - val_loss: 5.9677 - val_accuracy: 0.0519\n",
            "Epoch 59/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 7.6840 - accuracy: 0.0743 - val_loss: 5.9495 - val_accuracy: 0.0513\n",
            "Epoch 60/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.6837 - accuracy: 0.0731 - val_loss: 5.9659 - val_accuracy: 0.0520\n",
            "Epoch 61/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.6722 - accuracy: 0.0742 - val_loss: 5.9818 - val_accuracy: 0.0525\n",
            "Epoch 62/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.6588 - accuracy: 0.0744 - val_loss: 6.0218 - val_accuracy: 0.0498\n",
            "Epoch 63/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.6657 - accuracy: 0.0734 - val_loss: 6.0520 - val_accuracy: 0.0490\n",
            "Epoch 64/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 7.6244 - accuracy: 0.0763 - val_loss: 6.0656 - val_accuracy: 0.0501\n",
            "Epoch 65/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.5942 - accuracy: 0.0763 - val_loss: 6.0721 - val_accuracy: 0.0503\n",
            "Epoch 66/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.6074 - accuracy: 0.0758 - val_loss: 6.0862 - val_accuracy: 0.0493\n",
            "Epoch 67/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.5889 - accuracy: 0.0781 - val_loss: 6.0844 - val_accuracy: 0.0497\n",
            "Epoch 68/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 7.5807 - accuracy: 0.0773 - val_loss: 6.0940 - val_accuracy: 0.0510\n",
            "Epoch 69/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.5608 - accuracy: 0.0777 - val_loss: 6.1182 - val_accuracy: 0.0515\n",
            "Epoch 70/400\n",
            "41/40 [==============================] - 14s 333ms/step - loss: 7.5719 - accuracy: 0.0781 - val_loss: 6.1329 - val_accuracy: 0.0483\n",
            "Epoch 71/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 7.5655 - accuracy: 0.0792 - val_loss: 6.1753 - val_accuracy: 0.0483\n",
            "Epoch 72/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.5485 - accuracy: 0.0797 - val_loss: 6.1954 - val_accuracy: 0.0478\n",
            "Epoch 73/400\n",
            "41/40 [==============================] - 14s 332ms/step - loss: 7.5010 - accuracy: 0.0812 - val_loss: 6.2054 - val_accuracy: 0.0474\n",
            "Epoch 74/400\n",
            "41/40 [==============================] - 14s 333ms/step - loss: 7.4838 - accuracy: 0.0830 - val_loss: 6.2126 - val_accuracy: 0.0468\n",
            "Epoch 75/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.4882 - accuracy: 0.0837 - val_loss: 6.2321 - val_accuracy: 0.0472\n",
            "Epoch 76/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.4741 - accuracy: 0.0841 - val_loss: 6.2400 - val_accuracy: 0.0468\n",
            "Epoch 77/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.4601 - accuracy: 0.0848 - val_loss: 6.2034 - val_accuracy: 0.0473\n",
            "Epoch 78/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 7.4569 - accuracy: 0.0861 - val_loss: 6.1844 - val_accuracy: 0.0480\n",
            "Epoch 79/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.4511 - accuracy: 0.0868 - val_loss: 6.1986 - val_accuracy: 0.0493\n",
            "Epoch 80/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 7.4627 - accuracy: 0.0856 - val_loss: 6.2160 - val_accuracy: 0.0462\n",
            "Epoch 81/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.4908 - accuracy: 0.0831 - val_loss: 6.2182 - val_accuracy: 0.0474\n",
            "Epoch 82/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 7.4664 - accuracy: 0.0874 - val_loss: 6.2068 - val_accuracy: 0.0477\n",
            "Epoch 83/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.4158 - accuracy: 0.0900 - val_loss: 6.2487 - val_accuracy: 0.0472\n",
            "Epoch 84/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 7.3661 - accuracy: 0.0931 - val_loss: 6.2671 - val_accuracy: 0.0480\n",
            "Epoch 85/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.3607 - accuracy: 0.0946 - val_loss: 6.2838 - val_accuracy: 0.0493\n",
            "Epoch 86/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.3664 - accuracy: 0.0947 - val_loss: 6.3102 - val_accuracy: 0.0492\n",
            "Epoch 87/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.3584 - accuracy: 0.0960 - val_loss: 6.3293 - val_accuracy: 0.0498\n",
            "Epoch 88/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.3426 - accuracy: 0.0975 - val_loss: 6.3650 - val_accuracy: 0.0483\n",
            "Epoch 89/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 7.3629 - accuracy: 0.0963 - val_loss: 6.4091 - val_accuracy: 0.0460\n",
            "Epoch 90/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.3691 - accuracy: 0.0972 - val_loss: 6.3948 - val_accuracy: 0.0469\n",
            "Epoch 91/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 7.3107 - accuracy: 0.1004 - val_loss: 6.4055 - val_accuracy: 0.0462\n",
            "Epoch 92/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.3065 - accuracy: 0.1013 - val_loss: 6.4310 - val_accuracy: 0.0447\n",
            "Epoch 93/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 7.3015 - accuracy: 0.1021 - val_loss: 6.4405 - val_accuracy: 0.0445\n",
            "Epoch 94/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 7.2955 - accuracy: 0.1020 - val_loss: 6.4479 - val_accuracy: 0.0448\n",
            "Epoch 95/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.2859 - accuracy: 0.1038 - val_loss: 6.4710 - val_accuracy: 0.0444\n",
            "Epoch 96/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.2632 - accuracy: 0.1064 - val_loss: 6.5110 - val_accuracy: 0.0441\n",
            "Epoch 97/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 7.2721 - accuracy: 0.1070 - val_loss: 6.5745 - val_accuracy: 0.0422\n",
            "Epoch 98/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.2882 - accuracy: 0.1059 - val_loss: 6.5236 - val_accuracy: 0.0407\n",
            "Epoch 99/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 7.2773 - accuracy: 0.1079 - val_loss: 6.5417 - val_accuracy: 0.0392\n",
            "Epoch 100/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 7.2882 - accuracy: 0.1044 - val_loss: 6.5115 - val_accuracy: 0.0387\n",
            "Epoch 101/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.3165 - accuracy: 0.0996 - val_loss: 6.4578 - val_accuracy: 0.0461\n",
            "Epoch 102/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.2368 - accuracy: 0.1085 - val_loss: 6.4632 - val_accuracy: 0.0446\n",
            "Epoch 103/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 7.1962 - accuracy: 0.1142 - val_loss: 6.4747 - val_accuracy: 0.0446\n",
            "Epoch 104/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 7.1988 - accuracy: 0.1168 - val_loss: 6.4909 - val_accuracy: 0.0436\n",
            "Epoch 105/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 7.1420 - accuracy: 0.1219 - val_loss: 6.5151 - val_accuracy: 0.0426\n",
            "Epoch 106/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 7.1730 - accuracy: 0.1200 - val_loss: 6.5390 - val_accuracy: 0.0421\n",
            "Epoch 107/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 7.1573 - accuracy: 0.1242 - val_loss: 6.5606 - val_accuracy: 0.0421\n",
            "Epoch 108/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 7.1083 - accuracy: 0.1277 - val_loss: 6.5715 - val_accuracy: 0.0410\n",
            "Epoch 109/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 7.1079 - accuracy: 0.1295 - val_loss: 6.5796 - val_accuracy: 0.0405\n",
            "Epoch 110/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 7.1124 - accuracy: 0.1307 - val_loss: 6.6255 - val_accuracy: 0.0414\n",
            "Epoch 111/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 7.1081 - accuracy: 0.1312 - val_loss: 6.6623 - val_accuracy: 0.0421\n",
            "Epoch 112/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 7.0789 - accuracy: 0.1353 - val_loss: 6.6524 - val_accuracy: 0.0415\n",
            "Epoch 113/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 7.0821 - accuracy: 0.1372 - val_loss: 6.6380 - val_accuracy: 0.0413\n",
            "Epoch 114/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 7.0475 - accuracy: 0.1400 - val_loss: 6.6519 - val_accuracy: 0.0409\n",
            "Epoch 115/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 7.0063 - accuracy: 0.1429 - val_loss: 6.6854 - val_accuracy: 0.0407\n",
            "Epoch 116/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 6.9925 - accuracy: 0.1436 - val_loss: 6.7131 - val_accuracy: 0.0418\n",
            "Epoch 117/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 7.0076 - accuracy: 0.1452 - val_loss: 6.7456 - val_accuracy: 0.0415\n",
            "Epoch 118/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 7.0104 - accuracy: 0.1459 - val_loss: 6.7420 - val_accuracy: 0.0406\n",
            "Epoch 119/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 6.9984 - accuracy: 0.1481 - val_loss: 6.7275 - val_accuracy: 0.0407\n",
            "Epoch 120/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.9323 - accuracy: 0.1539 - val_loss: 6.7473 - val_accuracy: 0.0407\n",
            "Epoch 121/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.9733 - accuracy: 0.1539 - val_loss: 6.7815 - val_accuracy: 0.0411\n",
            "Epoch 122/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 6.9291 - accuracy: 0.1574 - val_loss: 6.7926 - val_accuracy: 0.0409\n",
            "Epoch 123/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 6.9359 - accuracy: 0.1568 - val_loss: 6.7878 - val_accuracy: 0.0390\n",
            "Epoch 124/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.8888 - accuracy: 0.1602 - val_loss: 6.8121 - val_accuracy: 0.0386\n",
            "Epoch 125/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.9042 - accuracy: 0.1605 - val_loss: 6.8316 - val_accuracy: 0.0399\n",
            "Epoch 126/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 6.8844 - accuracy: 0.1623 - val_loss: 6.8507 - val_accuracy: 0.0401\n",
            "Epoch 127/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.9299 - accuracy: 0.1609 - val_loss: 6.8698 - val_accuracy: 0.0400\n",
            "Epoch 128/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.8724 - accuracy: 0.1642 - val_loss: 6.8768 - val_accuracy: 0.0393\n",
            "Epoch 129/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.8770 - accuracy: 0.1653 - val_loss: 6.8501 - val_accuracy: 0.0403\n",
            "Epoch 130/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 6.8853 - accuracy: 0.1665 - val_loss: 6.8745 - val_accuracy: 0.0413\n",
            "Epoch 131/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.8868 - accuracy: 0.1669 - val_loss: 6.8984 - val_accuracy: 0.0410\n",
            "Epoch 132/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.8529 - accuracy: 0.1688 - val_loss: 6.8769 - val_accuracy: 0.0409\n",
            "Epoch 133/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.8515 - accuracy: 0.1717 - val_loss: 6.8780 - val_accuracy: 0.0417\n",
            "Epoch 134/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.8107 - accuracy: 0.1738 - val_loss: 6.8950 - val_accuracy: 0.0416\n",
            "Epoch 135/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.8046 - accuracy: 0.1743 - val_loss: 6.9071 - val_accuracy: 0.0424\n",
            "Epoch 136/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.8306 - accuracy: 0.1707 - val_loss: 6.9253 - val_accuracy: 0.0406\n",
            "Epoch 137/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.8390 - accuracy: 0.1683 - val_loss: 6.9649 - val_accuracy: 0.0384\n",
            "Epoch 138/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.8358 - accuracy: 0.1699 - val_loss: 7.0159 - val_accuracy: 0.0372\n",
            "Epoch 139/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 6.7880 - accuracy: 0.1805 - val_loss: 7.0126 - val_accuracy: 0.0370\n",
            "Epoch 140/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.7337 - accuracy: 0.1917 - val_loss: 6.9932 - val_accuracy: 0.0370\n",
            "Epoch 141/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.7345 - accuracy: 0.1951 - val_loss: 6.9872 - val_accuracy: 0.0371\n",
            "Epoch 142/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.7063 - accuracy: 0.1978 - val_loss: 7.0016 - val_accuracy: 0.0372\n",
            "Epoch 143/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.6804 - accuracy: 0.2005 - val_loss: 7.0273 - val_accuracy: 0.0369\n",
            "Epoch 144/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.6599 - accuracy: 0.2013 - val_loss: 7.0487 - val_accuracy: 0.0370\n",
            "Epoch 145/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.6822 - accuracy: 0.2009 - val_loss: 6.9963 - val_accuracy: 0.0361\n",
            "Epoch 146/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.6624 - accuracy: 0.2035 - val_loss: 7.0291 - val_accuracy: 0.0358\n",
            "Epoch 147/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.6810 - accuracy: 0.2033 - val_loss: 7.0719 - val_accuracy: 0.0358\n",
            "Epoch 148/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.6189 - accuracy: 0.2102 - val_loss: 7.0621 - val_accuracy: 0.0357\n",
            "Epoch 149/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.6128 - accuracy: 0.2115 - val_loss: 7.0792 - val_accuracy: 0.0356\n",
            "Epoch 150/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.6125 - accuracy: 0.2132 - val_loss: 7.1225 - val_accuracy: 0.0357\n",
            "Epoch 151/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.6052 - accuracy: 0.2141 - val_loss: 7.1476 - val_accuracy: 0.0349\n",
            "Epoch 152/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.6039 - accuracy: 0.2164 - val_loss: 7.1481 - val_accuracy: 0.0341\n",
            "Epoch 153/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.5545 - accuracy: 0.2170 - val_loss: 7.2031 - val_accuracy: 0.0347\n",
            "Epoch 154/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 6.6025 - accuracy: 0.2168 - val_loss: 7.2132 - val_accuracy: 0.0353\n",
            "Epoch 155/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.5706 - accuracy: 0.2191 - val_loss: 7.2567 - val_accuracy: 0.0352\n",
            "Epoch 156/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.5873 - accuracy: 0.2194 - val_loss: 7.2927 - val_accuracy: 0.0360\n",
            "Epoch 157/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.5892 - accuracy: 0.2218 - val_loss: 7.3348 - val_accuracy: 0.0353\n",
            "Epoch 158/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.5628 - accuracy: 0.2223 - val_loss: 7.3511 - val_accuracy: 0.0350\n",
            "Epoch 159/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 6.5632 - accuracy: 0.2191 - val_loss: 7.3580 - val_accuracy: 0.0358\n",
            "Epoch 160/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.5991 - accuracy: 0.2170 - val_loss: 7.3742 - val_accuracy: 0.0373\n",
            "Epoch 161/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.6601 - accuracy: 0.2013 - val_loss: 7.2402 - val_accuracy: 0.0386\n",
            "Epoch 162/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.7045 - accuracy: 0.1930 - val_loss: 7.0919 - val_accuracy: 0.0379\n",
            "Epoch 163/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.5766 - accuracy: 0.2118 - val_loss: 7.1770 - val_accuracy: 0.0369\n",
            "Epoch 164/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.5338 - accuracy: 0.2247 - val_loss: 7.2867 - val_accuracy: 0.0356\n",
            "Epoch 165/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 6.4757 - accuracy: 0.2324 - val_loss: 7.3177 - val_accuracy: 0.0348\n",
            "Epoch 166/400\n",
            "41/40 [==============================] - 14s 345ms/step - loss: 6.5243 - accuracy: 0.2354 - val_loss: 7.3418 - val_accuracy: 0.0343\n",
            "Epoch 167/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.4393 - accuracy: 0.2426 - val_loss: 7.3541 - val_accuracy: 0.0339\n",
            "Epoch 168/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.4130 - accuracy: 0.2469 - val_loss: 7.3668 - val_accuracy: 0.0340\n",
            "Epoch 169/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 6.4030 - accuracy: 0.2525 - val_loss: 7.3833 - val_accuracy: 0.0335\n",
            "Epoch 170/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.3749 - accuracy: 0.2544 - val_loss: 7.3966 - val_accuracy: 0.0331\n",
            "Epoch 171/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.3987 - accuracy: 0.2584 - val_loss: 7.4159 - val_accuracy: 0.0325\n",
            "Epoch 172/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.3802 - accuracy: 0.2597 - val_loss: 7.4316 - val_accuracy: 0.0326\n",
            "Epoch 173/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.3603 - accuracy: 0.2606 - val_loss: 7.4382 - val_accuracy: 0.0321\n",
            "Epoch 174/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.3637 - accuracy: 0.2616 - val_loss: 7.4390 - val_accuracy: 0.0326\n",
            "Epoch 175/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 6.3898 - accuracy: 0.2627 - val_loss: 7.4514 - val_accuracy: 0.0324\n",
            "Epoch 176/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.3627 - accuracy: 0.2640 - val_loss: 7.4572 - val_accuracy: 0.0323\n",
            "Epoch 177/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.3195 - accuracy: 0.2673 - val_loss: 7.4712 - val_accuracy: 0.0322\n",
            "Epoch 178/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.3506 - accuracy: 0.2675 - val_loss: 7.4760 - val_accuracy: 0.0325\n",
            "Epoch 179/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.3142 - accuracy: 0.2708 - val_loss: 7.5074 - val_accuracy: 0.0319\n",
            "Epoch 180/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.2802 - accuracy: 0.2754 - val_loss: 7.5280 - val_accuracy: 0.0317\n",
            "Epoch 181/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 6.2934 - accuracy: 0.2765 - val_loss: 7.5383 - val_accuracy: 0.0319\n",
            "Epoch 182/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.3141 - accuracy: 0.2749 - val_loss: 7.5565 - val_accuracy: 0.0319\n",
            "Epoch 183/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.2950 - accuracy: 0.2750 - val_loss: 7.5783 - val_accuracy: 0.0322\n",
            "Epoch 184/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.2713 - accuracy: 0.2763 - val_loss: 7.6118 - val_accuracy: 0.0315\n",
            "Epoch 185/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.2740 - accuracy: 0.2767 - val_loss: 7.6090 - val_accuracy: 0.0315\n",
            "Epoch 186/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.2696 - accuracy: 0.2743 - val_loss: 7.6239 - val_accuracy: 0.0304\n",
            "Epoch 187/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 6.3007 - accuracy: 0.2732 - val_loss: 7.6243 - val_accuracy: 0.0305\n",
            "Epoch 188/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.2866 - accuracy: 0.2721 - val_loss: 7.6114 - val_accuracy: 0.0299\n",
            "Epoch 189/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 6.3087 - accuracy: 0.2689 - val_loss: 7.6015 - val_accuracy: 0.0304\n",
            "Epoch 190/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.3186 - accuracy: 0.2655 - val_loss: 7.6187 - val_accuracy: 0.0296\n",
            "Epoch 191/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 6.3385 - accuracy: 0.2652 - val_loss: 7.6723 - val_accuracy: 0.0286\n",
            "Epoch 192/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.2923 - accuracy: 0.2720 - val_loss: 7.6958 - val_accuracy: 0.0285\n",
            "Epoch 193/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.2294 - accuracy: 0.2876 - val_loss: 7.7298 - val_accuracy: 0.0298\n",
            "Epoch 194/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.1976 - accuracy: 0.2976 - val_loss: 7.7451 - val_accuracy: 0.0302\n",
            "Epoch 195/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 6.1758 - accuracy: 0.3024 - val_loss: 7.7570 - val_accuracy: 0.0315\n",
            "Epoch 196/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 6.1053 - accuracy: 0.3066 - val_loss: 7.7762 - val_accuracy: 0.0306\n",
            "Epoch 197/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.1700 - accuracy: 0.3050 - val_loss: 7.7908 - val_accuracy: 0.0314\n",
            "Epoch 198/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 6.1235 - accuracy: 0.3075 - val_loss: 7.8033 - val_accuracy: 0.0307\n",
            "Epoch 199/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 6.1392 - accuracy: 0.3063 - val_loss: 7.8300 - val_accuracy: 0.0306\n",
            "Epoch 200/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.1520 - accuracy: 0.3061 - val_loss: 7.8373 - val_accuracy: 0.0306\n",
            "Epoch 201/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.1461 - accuracy: 0.3056 - val_loss: 7.8552 - val_accuracy: 0.0305\n",
            "Epoch 202/400\n",
            "41/40 [==============================] - 14s 332ms/step - loss: 6.1331 - accuracy: 0.3039 - val_loss: 7.8163 - val_accuracy: 0.0315\n",
            "Epoch 203/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 6.1198 - accuracy: 0.3079 - val_loss: 7.7758 - val_accuracy: 0.0316\n",
            "Epoch 204/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 6.1055 - accuracy: 0.3090 - val_loss: 7.7479 - val_accuracy: 0.0317\n",
            "Epoch 205/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 6.1047 - accuracy: 0.3104 - val_loss: 7.7783 - val_accuracy: 0.0316\n",
            "Epoch 206/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.0932 - accuracy: 0.3142 - val_loss: 7.8339 - val_accuracy: 0.0319\n",
            "Epoch 207/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 6.0552 - accuracy: 0.3204 - val_loss: 7.8759 - val_accuracy: 0.0319\n",
            "Epoch 208/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 6.0692 - accuracy: 0.3199 - val_loss: 7.9316 - val_accuracy: 0.0310\n",
            "Epoch 209/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 6.0707 - accuracy: 0.3258 - val_loss: 7.9576 - val_accuracy: 0.0302\n",
            "Epoch 210/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 6.0190 - accuracy: 0.3284 - val_loss: 7.9660 - val_accuracy: 0.0301\n",
            "Epoch 211/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.0519 - accuracy: 0.3282 - val_loss: 7.9691 - val_accuracy: 0.0299\n",
            "Epoch 212/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.0695 - accuracy: 0.3254 - val_loss: 7.9694 - val_accuracy: 0.0289\n",
            "Epoch 213/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 6.0365 - accuracy: 0.3288 - val_loss: 7.9655 - val_accuracy: 0.0285\n",
            "Epoch 214/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 6.0435 - accuracy: 0.3294 - val_loss: 7.9476 - val_accuracy: 0.0298\n",
            "Epoch 215/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.9960 - accuracy: 0.3348 - val_loss: 7.9287 - val_accuracy: 0.0309\n",
            "Epoch 216/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.9938 - accuracy: 0.3374 - val_loss: 7.9459 - val_accuracy: 0.0300\n",
            "Epoch 217/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.9635 - accuracy: 0.3409 - val_loss: 8.0120 - val_accuracy: 0.0310\n",
            "Epoch 218/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.9912 - accuracy: 0.3429 - val_loss: 8.0464 - val_accuracy: 0.0310\n",
            "Epoch 219/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 5.9724 - accuracy: 0.3454 - val_loss: 8.0696 - val_accuracy: 0.0310\n",
            "Epoch 220/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.9449 - accuracy: 0.3511 - val_loss: 8.1171 - val_accuracy: 0.0309\n",
            "Epoch 221/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 5.9695 - accuracy: 0.3506 - val_loss: 8.1222 - val_accuracy: 0.0310\n",
            "Epoch 222/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 5.9505 - accuracy: 0.3550 - val_loss: 8.1335 - val_accuracy: 0.0309\n",
            "Epoch 223/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 5.9368 - accuracy: 0.3553 - val_loss: 8.1348 - val_accuracy: 0.0309\n",
            "Epoch 224/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 5.9048 - accuracy: 0.3589 - val_loss: 8.1603 - val_accuracy: 0.0299\n",
            "Epoch 225/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 5.8819 - accuracy: 0.3603 - val_loss: 8.1657 - val_accuracy: 0.0298\n",
            "Epoch 226/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.8841 - accuracy: 0.3624 - val_loss: 8.1829 - val_accuracy: 0.0296\n",
            "Epoch 227/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.8490 - accuracy: 0.3676 - val_loss: 8.1915 - val_accuracy: 0.0298\n",
            "Epoch 228/400\n",
            "41/40 [==============================] - 14s 333ms/step - loss: 5.8771 - accuracy: 0.3653 - val_loss: 8.2064 - val_accuracy: 0.0295\n",
            "Epoch 229/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.8631 - accuracy: 0.3673 - val_loss: 8.2114 - val_accuracy: 0.0286\n",
            "Epoch 230/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 5.8519 - accuracy: 0.3660 - val_loss: 8.2225 - val_accuracy: 0.0285\n",
            "Epoch 231/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 5.8928 - accuracy: 0.3623 - val_loss: 8.2067 - val_accuracy: 0.0291\n",
            "Epoch 232/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 5.8777 - accuracy: 0.3620 - val_loss: 8.2275 - val_accuracy: 0.0297\n",
            "Epoch 233/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.8952 - accuracy: 0.3596 - val_loss: 8.2300 - val_accuracy: 0.0299\n",
            "Epoch 234/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.9257 - accuracy: 0.3595 - val_loss: 8.2277 - val_accuracy: 0.0312\n",
            "Epoch 235/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 5.8234 - accuracy: 0.3651 - val_loss: 8.2436 - val_accuracy: 0.0313\n",
            "Epoch 236/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 5.8636 - accuracy: 0.3654 - val_loss: 8.2751 - val_accuracy: 0.0304\n",
            "Epoch 237/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.8200 - accuracy: 0.3705 - val_loss: 8.3133 - val_accuracy: 0.0300\n",
            "Epoch 238/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.8226 - accuracy: 0.3760 - val_loss: 8.3569 - val_accuracy: 0.0297\n",
            "Epoch 239/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 5.8297 - accuracy: 0.3814 - val_loss: 8.4005 - val_accuracy: 0.0295\n",
            "Epoch 240/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.8198 - accuracy: 0.3860 - val_loss: 8.4091 - val_accuracy: 0.0300\n",
            "Epoch 241/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 5.7420 - accuracy: 0.3935 - val_loss: 8.4166 - val_accuracy: 0.0301\n",
            "Epoch 242/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.7796 - accuracy: 0.3928 - val_loss: 8.4193 - val_accuracy: 0.0304\n",
            "Epoch 243/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.7722 - accuracy: 0.3941 - val_loss: 8.4028 - val_accuracy: 0.0305\n",
            "Epoch 244/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.7538 - accuracy: 0.3962 - val_loss: 8.4117 - val_accuracy: 0.0298\n",
            "Epoch 245/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 5.7460 - accuracy: 0.3978 - val_loss: 8.4308 - val_accuracy: 0.0300\n",
            "Epoch 246/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 5.7588 - accuracy: 0.3983 - val_loss: 8.4508 - val_accuracy: 0.0300\n",
            "Epoch 247/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.7062 - accuracy: 0.4036 - val_loss: 8.4527 - val_accuracy: 0.0298\n",
            "Epoch 248/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.6994 - accuracy: 0.4045 - val_loss: 8.4668 - val_accuracy: 0.0296\n",
            "Epoch 249/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 5.7389 - accuracy: 0.4010 - val_loss: 8.4822 - val_accuracy: 0.0294\n",
            "Epoch 250/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.7144 - accuracy: 0.4031 - val_loss: 8.5022 - val_accuracy: 0.0300\n",
            "Epoch 251/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.7141 - accuracy: 0.4046 - val_loss: 8.5235 - val_accuracy: 0.0293\n",
            "Epoch 252/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.6844 - accuracy: 0.4052 - val_loss: 8.5164 - val_accuracy: 0.0299\n",
            "Epoch 253/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 5.7032 - accuracy: 0.4066 - val_loss: 8.5470 - val_accuracy: 0.0296\n",
            "Epoch 254/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 5.7149 - accuracy: 0.4074 - val_loss: 8.5484 - val_accuracy: 0.0301\n",
            "Epoch 255/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.6879 - accuracy: 0.4089 - val_loss: 8.5547 - val_accuracy: 0.0302\n",
            "Epoch 256/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.7113 - accuracy: 0.4056 - val_loss: 8.5678 - val_accuracy: 0.0304\n",
            "Epoch 257/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.6747 - accuracy: 0.4092 - val_loss: 8.6112 - val_accuracy: 0.0299\n",
            "Epoch 258/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.7014 - accuracy: 0.4079 - val_loss: 8.6238 - val_accuracy: 0.0298\n",
            "Epoch 259/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.6732 - accuracy: 0.4076 - val_loss: 8.6619 - val_accuracy: 0.0287\n",
            "Epoch 260/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 5.6673 - accuracy: 0.4074 - val_loss: 8.6936 - val_accuracy: 0.0288\n",
            "Epoch 261/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.7314 - accuracy: 0.4034 - val_loss: 8.7607 - val_accuracy: 0.0284\n",
            "Epoch 262/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.6871 - accuracy: 0.4066 - val_loss: 8.8143 - val_accuracy: 0.0285\n",
            "Epoch 263/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 5.6994 - accuracy: 0.4076 - val_loss: 8.8196 - val_accuracy: 0.0289\n",
            "Epoch 264/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.6778 - accuracy: 0.4102 - val_loss: 8.8015 - val_accuracy: 0.0296\n",
            "Epoch 265/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 5.6925 - accuracy: 0.4117 - val_loss: 8.8020 - val_accuracy: 0.0295\n",
            "Epoch 266/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 5.6466 - accuracy: 0.4176 - val_loss: 8.7784 - val_accuracy: 0.0291\n",
            "Epoch 267/400\n",
            "41/40 [==============================] - 14s 344ms/step - loss: 5.6662 - accuracy: 0.4207 - val_loss: 8.7784 - val_accuracy: 0.0283\n",
            "Epoch 268/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.6676 - accuracy: 0.4217 - val_loss: 8.7881 - val_accuracy: 0.0285\n",
            "Epoch 269/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 5.6491 - accuracy: 0.4278 - val_loss: 8.7935 - val_accuracy: 0.0284\n",
            "Epoch 270/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 5.6220 - accuracy: 0.4310 - val_loss: 8.7952 - val_accuracy: 0.0284\n",
            "Epoch 271/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.6525 - accuracy: 0.4296 - val_loss: 8.8253 - val_accuracy: 0.0288\n",
            "Epoch 272/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 5.5620 - accuracy: 0.4350 - val_loss: 8.8584 - val_accuracy: 0.0286\n",
            "Epoch 273/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.6081 - accuracy: 0.4288 - val_loss: 8.8940 - val_accuracy: 0.0283\n",
            "Epoch 274/400\n",
            "41/40 [==============================] - 14s 344ms/step - loss: 5.6294 - accuracy: 0.4268 - val_loss: 8.9604 - val_accuracy: 0.0283\n",
            "Epoch 275/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.6354 - accuracy: 0.4232 - val_loss: 8.9886 - val_accuracy: 0.0278\n",
            "Epoch 276/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.6311 - accuracy: 0.4234 - val_loss: 8.9550 - val_accuracy: 0.0281\n",
            "Epoch 277/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 5.5745 - accuracy: 0.4308 - val_loss: 8.9148 - val_accuracy: 0.0286\n",
            "Epoch 278/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.5864 - accuracy: 0.4368 - val_loss: 8.9178 - val_accuracy: 0.0291\n",
            "Epoch 279/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 5.5592 - accuracy: 0.4426 - val_loss: 8.9214 - val_accuracy: 0.0288\n",
            "Epoch 280/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.5434 - accuracy: 0.4459 - val_loss: 8.9408 - val_accuracy: 0.0283\n",
            "Epoch 281/400\n",
            "41/40 [==============================] - 14s 335ms/step - loss: 5.5363 - accuracy: 0.4479 - val_loss: 8.9552 - val_accuracy: 0.0282\n",
            "Epoch 282/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 5.5218 - accuracy: 0.4504 - val_loss: 8.9794 - val_accuracy: 0.0281\n",
            "Epoch 283/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.5207 - accuracy: 0.4500 - val_loss: 8.9836 - val_accuracy: 0.0288\n",
            "Epoch 284/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.5047 - accuracy: 0.4515 - val_loss: 8.9947 - val_accuracy: 0.0287\n",
            "Epoch 285/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 5.5161 - accuracy: 0.4499 - val_loss: 9.0212 - val_accuracy: 0.0286\n",
            "Epoch 286/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 5.5441 - accuracy: 0.4479 - val_loss: 9.0573 - val_accuracy: 0.0286\n",
            "Epoch 287/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.5439 - accuracy: 0.4479 - val_loss: 9.0907 - val_accuracy: 0.0282\n",
            "Epoch 288/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.5442 - accuracy: 0.4457 - val_loss: 9.0999 - val_accuracy: 0.0290\n",
            "Epoch 289/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.5411 - accuracy: 0.4465 - val_loss: 9.1041 - val_accuracy: 0.0293\n",
            "Epoch 290/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 5.5594 - accuracy: 0.4459 - val_loss: 9.1220 - val_accuracy: 0.0293\n",
            "Epoch 291/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.5317 - accuracy: 0.4473 - val_loss: 9.1205 - val_accuracy: 0.0295\n",
            "Epoch 292/400\n",
            "41/40 [==============================] - 14s 334ms/step - loss: 5.5383 - accuracy: 0.4468 - val_loss: 9.0733 - val_accuracy: 0.0292\n",
            "Epoch 293/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 5.5083 - accuracy: 0.4483 - val_loss: 9.0465 - val_accuracy: 0.0290\n",
            "Epoch 294/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.5105 - accuracy: 0.4522 - val_loss: 9.0644 - val_accuracy: 0.0285\n",
            "Epoch 295/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 5.4769 - accuracy: 0.4567 - val_loss: 9.1198 - val_accuracy: 0.0287\n",
            "Epoch 296/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 5.5149 - accuracy: 0.4577 - val_loss: 9.1595 - val_accuracy: 0.0287\n",
            "Epoch 297/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.4772 - accuracy: 0.4628 - val_loss: 9.1734 - val_accuracy: 0.0287\n",
            "Epoch 298/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 5.4780 - accuracy: 0.4659 - val_loss: 9.1669 - val_accuracy: 0.0288\n",
            "Epoch 299/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.4320 - accuracy: 0.4689 - val_loss: 9.1830 - val_accuracy: 0.0291\n",
            "Epoch 300/400\n",
            "41/40 [==============================] - 14s 337ms/step - loss: 5.4672 - accuracy: 0.4686 - val_loss: 9.2071 - val_accuracy: 0.0289\n",
            "Epoch 301/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.5072 - accuracy: 0.4667 - val_loss: 9.2263 - val_accuracy: 0.0288\n",
            "Epoch 302/400\n",
            "41/40 [==============================] - 14s 336ms/step - loss: 5.4542 - accuracy: 0.4706 - val_loss: 9.2414 - val_accuracy: 0.0286\n",
            "Epoch 303/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.3720 - accuracy: 0.4750 - val_loss: 9.2379 - val_accuracy: 0.0285\n",
            "Epoch 304/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 5.4327 - accuracy: 0.4725 - val_loss: 9.2519 - val_accuracy: 0.0286\n",
            "Epoch 305/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.4520 - accuracy: 0.4707 - val_loss: 9.2616 - val_accuracy: 0.0288\n",
            "Epoch 306/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.4554 - accuracy: 0.4704 - val_loss: 9.2703 - val_accuracy: 0.0285\n",
            "Epoch 307/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.4369 - accuracy: 0.4718 - val_loss: 9.2868 - val_accuracy: 0.0285\n",
            "Epoch 308/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.4547 - accuracy: 0.4695 - val_loss: 9.3024 - val_accuracy: 0.0286\n",
            "Epoch 309/400\n",
            "41/40 [==============================] - 14s 340ms/step - loss: 5.4407 - accuracy: 0.4713 - val_loss: 9.3420 - val_accuracy: 0.0281\n",
            "Epoch 310/400\n",
            "41/40 [==============================] - 14s 338ms/step - loss: 5.4257 - accuracy: 0.4711 - val_loss: 9.3502 - val_accuracy: 0.0284\n",
            "Epoch 311/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 5.4943 - accuracy: 0.4671 - val_loss: 9.3629 - val_accuracy: 0.0283\n",
            "Epoch 312/400\n",
            "41/40 [==============================] - 14s 344ms/step - loss: 5.4616 - accuracy: 0.4673 - val_loss: 9.3723 - val_accuracy: 0.0286\n",
            "Epoch 313/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.4598 - accuracy: 0.4665 - val_loss: 9.3883 - val_accuracy: 0.0280\n",
            "Epoch 314/400\n",
            "41/40 [==============================] - 14s 343ms/step - loss: 5.4938 - accuracy: 0.4651 - val_loss: 9.3820 - val_accuracy: 0.0287\n",
            "Epoch 315/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.4544 - accuracy: 0.4671 - val_loss: 9.4017 - val_accuracy: 0.0291\n",
            "Epoch 316/400\n",
            "41/40 [==============================] - 14s 339ms/step - loss: 5.4262 - accuracy: 0.4693 - val_loss: 9.4167 - val_accuracy: 0.0291\n",
            "Epoch 317/400\n",
            "41/40 [==============================] - 14s 342ms/step - loss: 5.4526 - accuracy: 0.4684 - val_loss: 9.4113 - val_accuracy: 0.0285\n",
            "Epoch 318/400\n",
            "41/40 [==============================] - 14s 341ms/step - loss: 5.4012 - accuracy: 0.4743 - val_loss: 9.4326 - val_accuracy: 0.0291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9f2ef54c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy9TC1K840p4"
      },
      "source": [
        "Define encoder model and decoder model from the main model, these will be part of the inference model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCSKoTKF0KZ"
      },
      "source": [
        "context_model = Model(input_context, encoder_states)\n",
        "#define the inputs for the decoder LSTM\n",
        "target_h = Input(shape = (LAYER_SIZE, ))\n",
        "target_c = Input(shape = (LAYER_SIZE, ))\n",
        "target_h1 = Input(shape = (LAYER_SIZE, ))\n",
        "target_c1 = Input(shape = (LAYER_SIZE, ))\n",
        "target_h3 = Input(shape = (LAYER_SIZE, ))\n",
        "target_c3 = Input(shape = (LAYER_SIZE, ))\n",
        "decoder_states_inputs = [target_h, target_c,target_h1,target_c1,target_h3,target_c3]\n",
        "# the decoder LSTM takes in the embedding of the initial word passed as input into the decoder model (the 'BOS' tag)\n",
        "# along with the final states of the encoder model, to output the corresponding sequences for 'BOS', and the new LSTM states.\n",
        "target, h, c = LSTM_DECODER(input_tar_embed, initial_state = decoder_states_inputs[:2])\n",
        "target2, h2, c2 = LSTM(LAYER_SIZE, return_state = True, return_sequences = True)(target, initial_state = decoder_states_inputs[2:4])\n",
        "target2, h3, c3 = LSTM(LAYER_SIZE, return_state = True, return_sequences = True)(target2, initial_state = decoder_states_inputs[4:6])\n",
        "\n",
        "decoder_states=[h,c,h2,c2,h3,c3]\n",
        "dec_output = Dense(vocab_size, activation = 'softmax')(target)\n",
        "target_model = Model(\n",
        "[input_target] + decoder_states_inputs,\n",
        "[dec_output] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlAk45SN5CzW"
      },
      "source": [
        "str_to_tokens is used to convert the question to a sequence of integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYjBL5Ef5ATK"
      },
      "source": [
        "# pass in the question to the encoder LSTM, to get the final encoder states of the encoder LSTM\n",
        "def str_to_tokens( sentence : str ):\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "    for word in words:\n",
        "        tokens_list.append(word_to_index[ word ] )\n",
        "    return sequence.pad_sequences( [tokens_list] , maxlen=20 , padding='post')\n",
        "# run the inference model\n",
        "question='where is it'\n",
        "#question=clean_text(question)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc8QD46u5aLO"
      },
      "source": [
        "Talk to the chatbot, the question is tokenized and then the predicition is applied. The data goes through the context and decoder models and is then produced.\n",
        "\n",
        "\n",
        "```\n",
        "for _ in range(1):\n",
        "```\n",
        "defines how many questions you want to ask in a row. in this case use\n",
        "\n",
        "```\n",
        "Input('Enter a question instead of a single question')\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lG7uBfE5Tck",
        "outputId": "4938d7ba-7e05-43a9-848a-8970a2c51a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for _ in range(1):\n",
        "\tstates_values = context_model.predict( str_to_tokens(question) )\n",
        "\ttarget_seq = np.zeros( ( 1 , 1) )\n",
        "\ttarget_seq[0, 0] = word_to_index['BOS']\n",
        "\tstop_condition = False\n",
        "\tresult = ''\n",
        "\twhile not stop_condition :\n",
        "\t\tdec_outputs , ha , ca, hb, cb,hc,cc= target_model.predict([ target_seq ] + states_values )\n",
        "\t\tsampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "\t\tsampled_word = None\n",
        "\t\tfor word , index in word_to_index.items() :\n",
        "\t\t\tif sampled_word_index == index :\n",
        "\t\t\t\tresult += ' {}'.format( word )\n",
        "\t\t\t\tsampled_word = word\n",
        "\n",
        "\t\tif sampled_word == 'EOS' or len(result.split()) > 10:\n",
        "\t\t\tstop_condition = True\n",
        "\t\ttarget_seq = np.zeros( ( 1 , 1 ) )\n",
        "\t\ttarget_seq[ 0 , 0 ] = sampled_word_index\n",
        "\t\tstates_values = [ ha , ca, hb, cb, hc, cc]\n",
        "\tprint( result )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " thomas Worry Worry Madrid. away. condition They're They're They're They're away. They're They're They're They're They're They're misses They're They're misses\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}